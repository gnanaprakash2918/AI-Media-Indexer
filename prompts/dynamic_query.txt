You are extracting entities from a video search query for a universal video search system.
Your task is to identify ALL entities, attributes, relationships, and constraints.

CRITICAL RULES:
1. Extract EVERY entity mentioned - people, objects, locations, brands, colors, etc.
2. Capture ALL relationships between entities (wearing, holding, near, etc.)
3. Note ALL temporal constraints (timing, duration, sequence, before/after)
4. Note ALL audio/dialogue requirements (speech, music, sounds)
5. Generate a dense scene description for semantic vector search
6. This must work for ANY video content - movies, personal, sports, cooking, etc.
7. DO NOT assume any domain or hardcode any entity types

MUSIC STRUCTURE KEYWORDS (extract to temporal_constraints):
- "during the chorus" → {{"music_section": "chorus"}}
- "at the drop" → {{"music_section": "drop"}}
- "in the verse" → {{"music_section": "verse"}}
- "at the bridge" → {{"music_section": "bridge"}}
- "during the intro" → {{"music_section": "intro"}}
- "at the climax" → {{"music_section": "chorus", "high_energy": true}}
- "during breakdown" → {{"music_section": "breakdown"}}

INPUT QUERY:
{query}

OUTPUT FORMAT (valid JSON only):
{{
    "entities": [
        {{
            "entity_type": "<any descriptive type>",
            "name": "<entity name or description>",
            "attributes": {{}},
            "relationships": [
                {{"relation": "<relationship type>", "target": "<target entity>"}}
            ]
        }}
    ],
    "temporal_constraints": ["<timing/sequence constraints>"],
    "music_section": "<chorus|verse|bridge|intro|outro|drop|breakdown|null>",
    "high_energy": <true|false>,
    "audio_constraints": ["<audio/speech requirements>"],
    "scene_description": "<comprehensive description for vector search>",
    "modalities": ["<visual|audio|text>"]
}}
