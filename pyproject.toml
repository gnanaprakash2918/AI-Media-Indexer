[build-system]
requires = ["hatchling>=1.26.0"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["ai_media_indexer"]

[[tool.uv.index]]
name = "pytorch-cu124"
url = "https://download.pytorch.org/whl/cu124"
explicit = true

[tool.hatch.metadata]
allow-direct-references = true

[project]
name = "ai-media-indexer"
version = "0.1.0"
description = "AI Media Indexer with SOTA Speech Recognition (NeMo/Whisper) and Voice Intelligence"
readme = "README.md"
requires-python = ">=3.10,<3.13"
dependencies = [
    "black>=24.0.0",
    "cmake>=3.20.0",
    "cython>=3.0.0",
    "faster-whisper>=1.1.0",
    "hf-transfer>=0.1.0",
    "hf-xet>=0.1.0",
    "langchain-core>=0.3.0",
    "langchain-google-genai>=2.0.0",
    "librosa>=0.10.0",
    "onnx==1.16.1",
    "ml_dtypes>=0.4.0,<0.6.0",
    # "nemo-toolkit[asr]>=1.23.0",
    "ninja>=1.11.0",
    "ollama>=0.6.1",
    "packaging",
    "pydantic>=2.10.0",
    "python-magic>=0.4.27",
    "python-magic-bin>=0.4.14; sys_platform == 'win32'",
    "ruff>=0.6.0",
    "scikit-learn>=1.5.0",
    "transformers==4.46.3",
    "torch==2.5.1",
    "torchaudio==2.5.1",
    "torchvision==0.20.1",
    "python-dotenv>=1.2.1",
    "pydantic-settings>=2.6.0",
    "qdrant-client>=1.16.2",
    "sentence-transformers>=3.3.0",
    "ctranslate2>=4.6.1",
    "mcp>=1.23.2",
    "websockets>=15.0.1",
    "httpx>=0.28.1",
    "langfuse>=3.11.0",
    "loguru>=0.7.2",
    "a2a>=0.44",
    "python-a2a>=0.5.10",
    "numpy>=1.26.0,<2.0.0",
    "a2a-sdk[all,http-server]>=0.3.20",
    "opencv-python-headless>=4.8.0",
    "uvicorn>=0.38.0",
    "fastapi>=0.124.2",
    "pillow>=12.0.0",
    "pyannote.audio>=3.1.1",
    "psutil>=5.9.0",
    "insightface>=0.7.3",
    "onnxruntime>=1.16.0",
    "hdbscan>=0.8.36",
    "easyocr>=1.7.1",
    "instructor>=1.13.0",
    "pytest>=9.0.2",
    "nvidia-ml-py>=12.535.0",
    "celery[redis]>=5.3.6",
    "redis>=5.0.1",
    "sam3 @ https://github.com/facebookresearch/sam3.git",
    # "brave-search>=0.1.0", # Removed due to httpx conflict
    "pyloudnorm>=0.1.1",
    "fer>=22.5.1",
    "deepface>=0.0.93",
    "ultralytics>=8.3.0",
    "paddleocr>=2.9.1",
    "decord>=0.6.0",
    "pycocotools>=2.0.0",
    "FlagEmbedding>=1.3.3",
    "rank_bm25>=0.2.2",
    "tf-keras>=2.16.0",  # Required for transformers compatibility with Keras 3
    "scenedetect[opencv]>=0.6.0",
    "triton @ https://github.com/woct0rdho/triton-windows/releases/download/v3.0.0-windows.post1/triton-3.0.0-cp312-cp312-win_amd64.whl ; sys_platform == 'win32'",
    "imagehash>=4.3.0",  # Perceptual hashing for content fingerprinting
    "open-clip-torch>=3.2.0",
    "hydra-core>=1.3.2",
    "neo4j>=6.1.0",
    "opencv-python>=4.11.0.86",
    "paddlepaddle>=3.3.0",
]

[project.optional-dependencies]
dev = ["black>=24.0.0", "mypy>=1.10.0", "pyright>=1.1.380"]
indic = [
    "nemo-toolkit[asr]>=1.23.0",
    "protobuf",
    "Cython>=3.0.0",
]

[tool.black]
line-length = 80
target-version = ["py312"]
skip-string-normalization = false

[tool.ruff]
line-length = 80
target-version = "py312"

[tool.ruff.lint]
select = ["E", "F", "W", "I", "N", "B", "C4", "D"]
ignore = ["D203", "D213", "E501", "B008"]

[tool.ruff.lint.isort]
combine-as-imports = true
known-first-party = ["ai_media_indexer"]

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.ruff.format]
line-ending = "lf"

[tool.uv]
cache-dir = ".uv_cache"
concurrent-downloads = 5

# Force torch packages to use CUDA 12.4 index
[tool.uv.sources]
torch = { index = "pytorch-cu124" }
torchaudio = { index = "pytorch-cu124" }
torchvision = { index = "pytorch-cu124" }
# Note: nemo-toolkit uses PyPI version. AI4Bharat models work with Whisper fallback.
