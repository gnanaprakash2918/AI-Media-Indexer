# AI Providers
OLLAMA_BASE_URL=http://localhost:11434
AGENT_MODEL=llama3.1
OLLAMA_MODEL=llama3.1
HF_TOKEN=your_token_here
HF_HUB_ENABLE_HF_TRANSFER=1

# Metadata
TMDB_API_KEY=your_tmdb_key_if_you_have_one

# Database
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Hardware
DEVICE_OVERRIDE=cuda

# Frontend (optional - defaults shown)
# VITE_API_URL=http://localhost:8000

# Processing Settings (tune for your hardware)
# Lower values = more processing, better detection, but slower and higher memory
FRAME_INTERVAL=5                    # Extract frames every N seconds (default: 5)
FRAME_SAMPLE_RATIO=2                # Process every Nth extracted frame (default: 2)
FACE_DETECTION_THRESHOLD=0.5        # Face confidence 0.3-0.9 (lower=more faces, default: 0.5)
FACE_DETECTION_RESOLUTION=640       # 320=fast, 640=balanced, 960=accurate (default: 640)

PYTHONPYCACHEPREFIX=.cache/pycache

# Langfuse Observability (Optional)
# Valid values: disabled, docker, cloud
LANGFUSE_BACKEND=disabled

# Docker Langfuse (uncomment if using local Docker instance)
# See docs/configuration.md for full setup instructions
# 1. Run: docker compose --profile docker up -d
# 2. Go to http://localhost:3300 and create account + project
# 3. Get API keys from Settings -> API Keys
# 4. Fill in the values below, then run start.ps1/start.sh (it auto-generates OTEL header)
# LANGFUSE_BACKEND=docker
# LANGFUSE_HOST=http://localhost:3300
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:3300/api/public/otel

# Cloud Langfuse (uncomment if using Langfuse Cloud)
# LANGFUSE_BACKEND=cloud
# LANGFUSE_HOST=https://cloud.langfuse.com
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
# OTEL_EXPORTER_OTLP_ENDPOINT=https://cloud.langfuse.com/api/public/otel

# This maps the backend setting to the Docker Profile system
COMPOSE_PROFILES=${LANGFUSE_BACKEND}
